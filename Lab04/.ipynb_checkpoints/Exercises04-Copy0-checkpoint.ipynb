{
 "metadata": {
  "name": "",
  "signature": "sha256:3cbf95ab33481656456528d69ede69297649811a56787cf2f6d8445054800b7f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 492
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.linalg as la\n",
      "import scipy.stats as st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 493
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 494
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 495
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Latent Semantic Analysis (LSA) is a method for reducing the dimnesionality of documents treated as a bag of words. It is used for document classification, clustering and retrieval. For example, LSA can be used to search for prior art given a new patent application. In this homework, we will implement a small library for simple latent semantic analysis as a practical example of the application of SVD. The ideas are very similar to PCA.\n",
      "\n",
      "We will implement a toy example of LSA to get familiar with the ideas. If you want to use LSA or similar methods for statiscal language analyis, the most efficient Python library is probably [gensim](https://radimrehurek.com/gensim/) - this also provides an online algorithm - i.e. the training information can be continuously updated. Other useful functions for processing natural language can be found in the [Natural Lnaguage Toolkit](http://www.nltk.org/)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note**: The SVD from scipy.linalg performs a full decomposition, which is inefficient since we only need to decompose until we get the first k singluar values. If the SVD from `scipy.linalg` is too slow, please use the `sparsesvd` function from the [sparsesvd](https://pypi.python.org/pypi/sparsesvd/) package to perform SVD instead.  You can install in the usual way with \n",
      "```\n",
      "!pip install sparsesvd\n",
      "```\n",
      "\n",
      "Then import the following\n",
      "```python\n",
      "from sparsesvd import sparsesvd \n",
      "from scipy.sparse import csc_matrix \n",
      "```\n",
      "\n",
      "and use as follows\n",
      "```python\n",
      "sparsesvd(csc_matrix(M), k=10)\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sparsesvd import sparsesvd \n",
      "from scipy.sparse import csc_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 496
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 1 (10 points)**.  Calculating pairwise distance matrices.\n",
      "\n",
      "Suppose we want to construct a distance matrix between the rows of a matrix. For example, given the matrix \n",
      "\n",
      "```python\n",
      "M = np.array([[1,2,3],[4,5,6]])\n",
      "```\n",
      "\n",
      "the distance matrix using Euclidean distance as the measure would be\n",
      "```python\n",
      "[[ 0.000  1.414  2.828]\n",
      " [ 1.414  0.000  1.414]\n",
      " [ 2.828  1.414  0.000]] \n",
      "```\n",
      "if $M$ was a collection of column vectors.\n",
      "\n",
      "Write a function to calculate the pairwise-distance matrix given the matrix $M$ and some arbitrary distance function. Your functions should have the following signature:\n",
      "```\n",
      "def func_name(M, distance_func):\n",
      "    pass\n",
      "```\n",
      "\n",
      "0. Write a distance function for the Euclidean, squared Euclidean and cosine measures.\n",
      "1. Write the function using looping for M as a collection of row vectors.\n",
      "2. Write the function using looping for M as a collection of column vectors.\n",
      "3. Wrtie the function using broadcasting for M as a colleciton of row vectors.\n",
      "4. Write the function using broadcasting for M as a colleciton of column vectors. \n",
      "\n",
      "For 3 and 4, try to avoid using transposition (but if you get stuck, there will be no penalty for using transpoition). Check that all four functions give the same result when applied to the given matrix $M$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "M = np.array([[1,2,3],[4,5,6]])\n",
      "# M is a 2*3 matrix, with three column vectors\n",
      "\n",
      "# Including row/column broadcasting parameters in the THREE functions is better,\n",
      "# but since numpy user-defined functions can have the same name but different signatures,\n",
      "# you can define Euclidean(a, b) and Euclidean(pts)\n",
      "def Euclidean(a, b):\n",
      "    return np.linalg.norm(a-b)\n",
      "\n",
      "def Euclidean_fast(pts): # vectorized to calculate the row distances\n",
      "    \"\"\"Euclidean distance with broadcasting\"\"\"\n",
      "    return np.sum((pts[None,:] - pts[:, None])**2, axis=-1)**0.5\n",
      "\n",
      "def Euclidean_squared(a, b):\n",
      "    return np.linalg.norm(a-b)**2\n",
      "\n",
      "def Euclidean_squared_fast(pts): # vectorized to calculate the row distances\n",
      "    \"\"\"Euclidean squared distance with broadcasting\"\"\"\n",
      "    return np.sum((pts[None,:] - pts[:, None])**2, axis=-1)\n",
      "\n",
      "def cosine(a, b):\n",
      "    \"\"\"Cosine distance\"\"\"\n",
      "    return (1 - np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b)))\n",
      "\n",
      "def cosine_fast(M): # vectorized to calculate the row distances\n",
      "    \"\"\"Cosine distance with broadcasting\"\"\"\n",
      "    row, col = M.shape\n",
      "    a = np.sqrt(np.sum(M[None,:]**2,axis=-1)) # columns only\n",
      "    b = np.sqrt(np.sum(M[:,None]**2,axis=-1)) # rows only\n",
      "    denominator = a[:,None]*b[None,:]\n",
      "    numerator = np.sum(M[:,None]*M[None,:],axis=-1)\n",
      "    ones = np.ones((row,1))\n",
      "    return (ones-numerator/denominator)\n",
      "\n",
      "# Column broadcasting: just use transpose, i.e. M.T\n",
      "\n",
      "# a = np.array([1,2])\n",
      "# b = np.array([3,4])\n",
      "# print Euclidean(a,b)\n",
      "# print Euclidean_squared(a,b)\n",
      "# print cosine(a,b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 497
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Why are my output from the row vectors different?\n",
      "# This is correct because there are only two row vectors in M\n",
      "\n",
      "def function2(M, distance_func):\n",
      "    \"\"\"using looping for M as a collection of row vectors\n",
      "        distance_func = {Euclidean, Euclidean_squared, cosine}\"\"\"\n",
      "    # M.shape[0] == number of rows / M.shape[1] == number of columns\n",
      "    dist = np.zeros((M.shape[0],M.shape[0])) # initialization\n",
      "    for i in range(M.shape[0]):\n",
      "        for j in range(i,M.shape[0]):\n",
      "            dist[i,j] = distance_func(M[i,:],M[j,:])\n",
      "    \n",
      "    # Then \"reflect\" the upper triangular part to the lower triangular one\n",
      "    dist = dist + dist.T - np.diag(dist.diagonal())\n",
      "    return dist\n",
      "\n",
      "print function2(M,Euclidean),'\\n'\n",
      "print function2(M,Euclidean_squared),'\\n'\n",
      "print function2(M,cosine)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.000  5.196]\n",
        " [ 5.196  0.000]] \n",
        "\n",
        "[[ 0.000  27.000]\n",
        " [ 27.000  0.000]] \n",
        "\n",
        "[[ 0.000  0.025]\n",
        " [ 0.025  0.000]]\n"
       ]
      }
     ],
     "prompt_number": 498
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def function3(M, distance_func):\n",
      "    \"\"\"using looping for M as a collection of column vectors\n",
      "        distance_func = {Euclidean, Euclidean_squared, cosine}\"\"\"\n",
      "    # M.shape[0] == number of rows / M.shape[1] == number of columns\n",
      "    dist = np.zeros((M.shape[1],M.shape[1])) # initialization\n",
      "    for i in range(M.shape[1]):\n",
      "        for j in range(i,M.shape[1]):\n",
      "            dist[i,j] = distance_func(M[:,i],M[:,j])\n",
      "    \n",
      "    # Then \"reflect\" the lower triangular part to the upper triangular one\n",
      "    dist = dist + dist.T - np.diag(dist.diagonal())\n",
      "    return dist\n",
      "\n",
      "print function3(M,Euclidean),'\\n'\n",
      "print function3(M,Euclidean_squared),'\\n'\n",
      "print function3(M,cosine)\n",
      "# M.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.000  1.414  2.828]\n",
        " [ 1.414  0.000  1.414]\n",
        " [ 2.828  1.414  0.000]] \n",
        "\n",
        "[[ 0.000  2.000  8.000]\n",
        " [ 2.000  0.000  2.000]\n",
        " [ 8.000  2.000  0.000]] \n",
        "\n",
        "[[ 0.000  0.009  0.024]\n",
        " [ 0.009 -0.000  0.003]\n",
        " [ 0.024  0.003  0.000]]\n"
       ]
      }
     ],
     "prompt_number": 374
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def function4(M, distance_func):\n",
      "    \"\"\"using broadcasting for M as a collection of row vectors\n",
      "        distance_func = {Euclidean_fast, Euclidean_squared_fast, cosine_fast}\"\"\"\n",
      "    # M.shape[0] == number of rows / M.shape[1] == number of columns\n",
      "    return distance_func(M)\n",
      "\n",
      "print function4(M,Euclidean_fast),'\\n'\n",
      "print function4(M,Euclidean_squared_fast),'\\n'\n",
      "print function4(M,cosine_fast)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.000  5.196]\n",
        " [ 5.196  0.000]] \n",
        "\n",
        "[[ 0 27]\n",
        " [27  0]] \n",
        "\n",
        "[[[ 0.000  0.025]\n",
        "  [ 0.025  0.000]]]\n"
       ]
      }
     ],
     "prompt_number": 313
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def function5(M, distance_func):\n",
      "    \"\"\"using broadcasting for M as a collection of column vectors\n",
      "        distance_func = {Euclidean_fast, Euclidean_squared_fast, cosine_fast}\"\"\"\n",
      "    # M.shape[0] == number of rows / M.shape[1] == number of columns\n",
      "    return distance_func(M.T)\n",
      "\n",
      "print function5(M,Euclidean_fast),'\\n'\n",
      "print function5(M,Euclidean_squared_fast),'\\n'\n",
      "print function5(M,cosine_fast)\n",
      "# M.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.000  1.414  2.828]\n",
        " [ 1.414  0.000  1.414]\n",
        " [ 2.828  1.414  0.000]] \n",
        "\n",
        "[[0 2 8]\n",
        " [2 0 2]\n",
        " [8 2 0]] \n",
        "\n",
        "[[[ 0.000  0.009  0.024]\n",
        "  [ 0.009 -0.000  0.003]\n",
        "  [ 0.024  0.003  0.000]]]\n"
       ]
      }
     ],
     "prompt_number": 314
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 2 (10 points)**. Write 3 functions to calculate the term frequency (tf), the inverse document frequency (idf) and the product (tf-idf). Each function should take a single argument `docs`, which is a dictionary of (key=identifier, value=dcoument text) pairs, and return an appropriately sized array. Convert '-' to ' ' (space), remove punctuation, convert text to lowercase and split on whitespace to generate a collection of terms from the dcoument text.\n",
      "\n",
      "- tf = the number of occurrences of term $i$ in document $j$\n",
      "- idf = $\\log \\frac{n}{1 + \\text{df}_i}$ where $n$ is the total number of documents and $\\text{df}_i$ is the number of documents in which term $i$ occurs.\n",
      "\n",
      "Print the table of tf-idf values for the following document collection\n",
      "\n",
      "```\n",
      "s1 = \"The quick brown fox\"\n",
      "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
      "s3 = \"The the the lazy dog elephant.\"\n",
      "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
      "\n",
      "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}\n",
      "```\n",
      "\n",
      "Note: You can use either a numpy array or pandas dataframe to store the matrix. However, we suggest using a Pandas dataframe since that will allow you to keep track of the row (term) and column (document) names in a single object. Of course, you could also maintain a numpy matrix, a list of terms, and a list of documents separately if you prefer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s1 = \"The quick brown fox\"\n",
      "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
      "s3 = \"The the the lazy dog elephant.\"\n",
      "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
      "\n",
      "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 499
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
      "\n",
      "def tf(docs):\n",
      "    \"\"\"tf scores: the number of occurrences of term i in document j\n",
      "       Return: wordUnion (words), initMat (tf scores), separate (document names)\"\"\"\n",
      "    # Step 1: clean up the docs and split into words\n",
      "    import string\n",
      "    from string import punctuation\n",
      "    # Convert '-' to ' ' (space), remove punctuation, convert text to lowercase\n",
      "    clean = docs.copy()\n",
      "    for name in docs:\n",
      "        temp = docs[name]\n",
      "        clean[name] = temp.replace('-',' ')\n",
      "        clean[name] = ''.join([c for c in clean[name] if c not in punctuation])\n",
      "        clean[name] = clean[name].lower()\n",
      "    \n",
      "    # Step 2: find the union of all words from the docs\n",
      "    separate = clean.copy()\n",
      "    wordUnion = set()\n",
      "    for name in clean:\n",
      "        separate[name] = clean[name].split() \n",
      "        # use the default split, so \"\\r\" and \"\\n\" will be removed automatically\n",
      "        wordUnion = wordUnion.union(set(separate[name]))\n",
      "    wordUnion = sorted(wordUnion)\n",
      "    separate = sorted(separate)\n",
      "    \n",
      "    # Step 3: calculate the frequency of each word\n",
      "    # Generate a matrix: column = each word, row = each document\n",
      "    # How to make an np.array with headers for rows and columns?\n",
      "    initMat = np.zeros((len(separate),len(wordUnion)))\n",
      "    for i in range(len(wordUnion)):\n",
      "        j = 0\n",
      "        for name in separate:\n",
      "            string = clean[name]\n",
      "            initMat[j,i] = string.count(wordUnion[i])\n",
      "            j += 1\n",
      "    return wordUnion, initMat, separate\n",
      "\n",
      "# wordUnion, initMat, separate = tf(docs)    \n",
      "# print wordUnion\n",
      "# print initMat\n",
      "# print initMat.shape\n",
      "# print separate\n",
      "# print \"-----------\"\n",
      "\n",
      "def idf(docs):\n",
      "    \"\"\"Return the idf scores: idf_i = log(n/(1+df_i)),\n",
      "    df_i = # of documents in which term i occurs\"\"\"\n",
      "    wordUnion, initMat, separate = tf(docs)\n",
      "    df_array = np.sum(initMat != 0,axis=0) # add up the df_i for each word\n",
      "    return np.log(len(docs)/(1.0+df_array))\n",
      "    # pass # null operation\n",
      "\n",
      "# idontfly = idf(docs)\n",
      "# print initMat\n",
      "# print idontfly\n",
      "\n",
      "# text = initMat * idontfly\n",
      "# print text.shape\n",
      "# print text\n",
      "\n",
      "def tfidf(docs):\n",
      "    \"\"\"Return the tf-idf scores:\n",
      "       Return: initMat*idontfly (tf scores), wordUnion (words), separate (document names)\"\"\"\n",
      "    wordUnion, initMat, separate = tf(docs)\n",
      "    idontfly = idf(docs)\n",
      "    return initMat*idontfly, wordUnion, separate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 500
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidfScores, wordUnion, separate = tfidf(docs)\n",
      "print \"The tf-idf scores are:\\n\", tfidfScores\n",
      "print \"The row names are: \", separate\n",
      "print \"The column names are: \",wordUnion"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The tf-idf scores are:\n",
        "[[ 0.288  0.000  0.000  0.288  0.000  0.000  0.000  0.000  0.000  0.693\n",
        "  -0.223  0.000]\n",
        " [ 0.288  0.000  0.000  0.288  2.773  0.000  0.000  0.693  0.000  0.000\n",
        "  -0.223  0.000]\n",
        " [ 0.000  0.288  0.288  0.000  0.000  0.693  0.000  0.000  0.000  0.000\n",
        "  -0.669  0.000]\n",
        " [ 0.000  0.288  0.288  0.000  0.000  0.000  0.693  0.000  0.693  0.000\n",
        "  -1.116  0.693]]\n",
        "The row names are:  ['s1', 's2', 's3', 's4']\n",
        "The column names are:  ['brown', 'dog', 'elephant', 'fox', 'jumps', 'lazy', 'lion', 'over', 'peacock', 'quick', 'the', 'tiger']\n"
       ]
      }
     ],
     "prompt_number": 317
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 3 (10 points)**. \n",
      "\n",
      "1. Write a function that takes a matrix $M$ and an integer $k$ as arguments, and reconstructs a reduced matrix using only the $k$ largest singular values. Use the `scipy.linalg.svd` function to perform the decomposition. This is the least squares approximation to the matrix $M$ in $k$ dimensions.\n",
      "\n",
      "2. Apply the function you just wrote to the following term-frequency matrix for a set of $9$ documents using $k=2$ and print the reconstructed matrix $M'$.\n",
      "```\n",
      "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
      "```\n",
      "\n",
      "3. Calculate the pairwise correlation matrix for the original matrix M and the reconstructed matrix using $k=2$ singular values (you may use [scipy.stats.spearmanr](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html) to do the calculations). Consider the first 5 sets of documents as one group $G1$ and the last 4 as another group $G2$ (i.e. first 5 and last 4 columns). What is the average within group correlation for $G1$, $G2$ and the average cross-group correlation for G1-G2 using either $M$ or $M'$. (Do not include self-correlation in the within-group calculations.)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
      "# np.set_printoptions()\n",
      "\n",
      "def leastSquares(M, k):\n",
      "    \"\"\"The least square approximation to the matrix M in k dimensions\"\"\"\n",
      "    # X = U*sigma*V\n",
      "    # (mxn) = (mxm)(mxn)(nxn)\n",
      "    # New: X = U*sigma*V\n",
      "    # (mxn) = (mxp)(pxp)(pxn)\n",
      "    import scipy.linalg as la\n",
      "    U, s, V = la.svd(M, full_matrices=False)\n",
      "    s_new = s[0:k] # indices: the last boundary is NOT included\n",
      "    U_new = U[:,0:k]\n",
      "    V_new = V[0:k,:]\n",
      "    return np.dot(U_new, np.dot(np.diag(s_new),V_new))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 501
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "    [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "    [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "    [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
      "\n",
      "M_new = leastSquares(M,2)\n",
      "print \"Least-squares approximated M' with 2 singular values:\\n\",M_new\n",
      "# U, s, V = la.svd(M_new, full_matrices=False)\n",
      "# np.dot(U,np.dot(np.diag(s),V))\n",
      "# print U\n",
      "# print s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Least-squares approximated M' with 2 singular values:\n",
        "[[ 0.162  0.400  0.379  0.468  0.176 -0.053 -0.115 -0.159 -0.092]\n",
        " [ 0.141  0.370  0.329  0.400  0.165 -0.033 -0.071 -0.097 -0.043]\n",
        " [ 0.152  0.505  0.358  0.410  0.236  0.024  0.060  0.087  0.124]\n",
        " [ 0.258  0.841  0.606  0.697  0.392  0.033  0.083  0.122  0.187]\n",
        " [ 0.449  1.234  1.051  1.266  0.556 -0.074 -0.155 -0.210 -0.049]\n",
        " [ 0.160  0.582  0.375  0.417  0.277  0.056  0.132  0.189  0.217]\n",
        " [ 0.160  0.582  0.375  0.417  0.277  0.056  0.132  0.189  0.217]\n",
        " [ 0.218  0.550  0.511  0.628  0.243 -0.065 -0.143 -0.197 -0.108]\n",
        " [ 0.097  0.532  0.230  0.212  0.267  0.137  0.315  0.444  0.425]\n",
        " [-0.061  0.232 -0.139 -0.266  0.145  0.240  0.546  0.767  0.664]\n",
        " [-0.065  0.335 -0.146 -0.301  0.203  0.306  0.695  0.977  0.849]\n",
        " [-0.043  0.254 -0.097 -0.208  0.152  0.221  0.503  0.707  0.616]]\n"
       ]
      }
     ],
     "prompt_number": 502
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rho1, pval1 = st.spearmanr(M)\n",
      "print \"Pairwise correlation matrix for the original M:\"\n",
      "print np.array(rho1),'\\n'\n",
      "\n",
      "rho2, pval2 = st.spearmanr(M_new)\n",
      "print \"Pairwise correlation matrix for the least-squares approximated M':\"\n",
      "print np.array(rho2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pairwise correlation matrix for the original M:\n",
        "[[ 1.000 -0.192  0.000  0.073 -0.333 -0.174 -0.258 -0.333 -0.333]\n",
        " [-0.192  1.000  0.000 -0.127  0.577 -0.302 -0.447 -0.577 -0.192]\n",
        " [ 0.000  0.000  1.000  0.438  0.000 -0.213 -0.316 -0.408 -0.408]\n",
        " [ 0.073 -0.127  0.438  1.000 -0.330 -0.172 -0.256 -0.330 -0.330]\n",
        " [-0.333  0.577  0.000 -0.330  1.000 -0.174 -0.258 -0.333 -0.333]\n",
        " [-0.174 -0.302 -0.213 -0.172 -0.174  1.000  0.674  0.522 -0.174]\n",
        " [-0.258 -0.447 -0.316 -0.256 -0.258  0.674  1.000  0.775  0.258]\n",
        " [-0.333 -0.577 -0.408 -0.330 -0.333  0.522  0.775  1.000  0.556]\n",
        " [-0.333 -0.192 -0.408 -0.330 -0.333 -0.174  0.258  0.556  1.000]] \n",
        "\n",
        "Pairwise correlation matrix for the least-squares approximated M':\n",
        "[[ 1.000  0.846  1.000  0.998  0.719 -0.837 -0.837 -0.837 -0.802]\n",
        " [ 0.846  1.000  0.846  0.844  0.972 -0.557 -0.557 -0.557 -0.480]\n",
        " [ 1.000  0.846  1.000  0.998  0.719 -0.837 -0.837 -0.837 -0.802]\n",
        " [ 0.998  0.844  0.998  1.000  0.718 -0.839 -0.839 -0.839 -0.804]\n",
        " [ 0.719  0.972  0.719  0.718  1.000 -0.389 -0.389 -0.389 -0.298]\n",
        " [-0.837 -0.557 -0.837 -0.839 -0.389  1.000  1.000  1.000  0.979]\n",
        " [-0.837 -0.557 -0.837 -0.839 -0.389  1.000  1.000  1.000  0.979]\n",
        " [-0.837 -0.557 -0.837 -0.839 -0.389  1.000  1.000  1.000  0.979]\n",
        " [-0.802 -0.480 -0.802 -0.804 -0.298  0.979  0.979  0.979  1.000]]\n"
       ]
      }
     ],
     "prompt_number": 503
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def corrWithin(G):\n",
      "    \"\"\"Return the average correlation within the column vectors group\"\"\"\n",
      "    ncol = G.shape[1]\n",
      "    corrSum = 0.0\n",
      "    for i in range(0,ncol):\n",
      "        for j in range(i,ncol):\n",
      "            corrMat = np.corrcoef(G[:,i],G[:,j])\n",
      "            corrSum += corrMat[0,1]\n",
      "    corrSum -= ncol\n",
      "    operations = ncol*(ncol-1)/2\n",
      "    return (corrSum/operations) # remove self-correlation\n",
      "\n",
      "def corrBetween(G1,G2):\n",
      "    \"\"\"Return the average cross-group correlation for two column vectors groups\"\"\"\n",
      "    ncol1 = G1.shape[1]\n",
      "    ncol2 = G2.shape[1]\n",
      "    corrSum = 0.0\n",
      "    for i in range(0,ncol1):\n",
      "        for j in range(0,ncol2):\n",
      "            corrMat = np.corrcoef(G1[:,i],G2[:,j])\n",
      "            corrSum += corrMat[0,1]\n",
      "    return (corrSum/(ncol1*ncol2))\n",
      "\n",
      "# Using M\n",
      "G1 = M[:,:5] # First 5 columns\n",
      "G2 = M[:,5:] # Last 4 columns\n",
      "print \"Using the original M:\"\n",
      "print \"Correlation within G1:\",corrWithin(G1)\n",
      "print \"Correlation within G2:\",corrWithin(G2)\n",
      "print \"Correlation between G1 and G2:\",corrBetween(G1,G2),'\\n'\n",
      "\n",
      "# Using M_new\n",
      "G1 = M_new[:,:5] # First 5 columns\n",
      "G2 = M_new[:,5:] # Last 4 columns\n",
      "print \"Using the the least-squares approximated M':\"\n",
      "print \"Correlation within G1:\",corrWithin(G1)\n",
      "print \"Correlation within G2:\",corrWithin(G2)\n",
      "print \"Correlation between G1 and G2:\",corrBetween(G1,G2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using the original M:\n",
        "Correlation within G1: 0.0215415737464\n",
        "Correlation within G2: 0.43511771482\n",
        "Correlation between G1 and G2: -0.303988025078 \n",
        "\n",
        "Using the the least-squares approximated M':\n",
        "Correlation within G1: 0.918795192066\n",
        "Correlation within G2: 0.998462087802\n",
        "Correlation between G1 and G2: -0.70525566678\n"
       ]
      }
     ],
     "prompt_number": 504
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 4 (20 points)**. Clustering with LSA\n",
      "\n",
      "1. Begin by loading a pubmed database of selected article titles using 'cPickle'. With the following:\n",
      "```import cPickle\n",
      "docs = cPickle.load(open('pubmed.pic'))```\n",
      "\n",
      "    Create a tf-idf matrix for every term that appears at least once in any of the documents. What is the shape of the tf-idf matrix? \n",
      "\n",
      "2. Perform SVD on the tf-idf matrix to obtain $U \\Sigma V^T$ (often written as $T \\Sigma D^T$ in this context with $T$ representing the terms and $D$ representing the documents). If we set all but the top $k$ singular values to 0, the reconstructed matrix is essentially $U_k \\Sigma_k V_k^T$, where $U_k$ is $m \\times k$, $\\Sigma_k$ is $k \\times k$ and $V_k^T$ is $k \\times n$. Terms in this reduced space are represented by $U_k \\Sigma_k$ and documents by $\\Sigma_k V^T_k$. Reconstruct the matrix using the first $k=10$ singular values.\n",
      "\n",
      "3. Use agglomerative hierachical clustering with complete linkage to plot a dendrogram and comment on the likely number of  document clusters with $k = 100$. Use the dendrogram function from [SciPy ](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.cluster.hierarchy.dendrogram.html).\n",
      "\n",
      "4. Determine how similar each of the original documents is to the new document `mystery.txt`. Since $A = U \\Sigma V^T$, we also have $V = A^T U \\Sigma^{-1}$ using orthogonality and the rule for transposing matrix products. This suggests that in order to map the new document to the same concept space, first find the tf-idf vector $v$ for the new document - this must contain all (and only) the terms present in the existing tf-idf matrix. Then the query vector $q$ is given by $v^T U_k \\Sigma_k^{-1}$. Find the 10 documents most similar to the new document and the 10 most dissimilar. \n",
      "\n",
      "5. Many documents often have some boilerplate material such as organization information, Copyright, etc. at the front or back of the document. Does it matter that the front and back matter of each document is essentially identical for either LSA-based clustering (part 3) or information retrieval (part 4)? Why or why not?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question 1\n",
      "docs = cPickle.load(open('pubmed.pic'))\n",
      "tfidfScores, wordUnion, separate = tfidf(docs)\n",
      "\n",
      "# Need to remove all numbers and punctuation in the tfidf (call the tf function to do this!!!)\n",
      "print \"The size of TF-IDF matrix is:\",tfidfScores.shape\n",
      "print \"There are\",tfidfScores.shape[0],\"documents\"\n",
      "print \"These documents contain\",tfidfScores.shape[1],\"words in total\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The size of TF-IDF matrix is: (178, 6488)\n",
        "There are 178 documents\n",
        "These documents contain 6488 words in total\n"
       ]
      }
     ],
     "prompt_number": 505
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question 2\n",
      "# X = U*sigma*V\n",
      "# (mxn) = (mxm)(mxn)(nxn)\n",
      "# New: X = U*sigma*V\n",
      "# (mxn) = (mxp)(pxp)(pxn)\n",
      "import scipy.linalg as la\n",
      "U, s, V = la.svd(tfidfScores, full_matrices=False)\n",
      "\n",
      "tfidf_new = leastSquares(tfidfScores,10)\n",
      "print \"Reconstructed TF-IDF scores matrix with only 10 singular values:\"\n",
      "print tfidf_new.shape\n",
      "print tfidf_new"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reconstructed TF-IDF scores matrix with only 10 singular values:\n",
        "(178, 6488)\n",
        "[[ 0.610  0.007 -0.072 ...,  0.006  0.047  0.009]\n",
        " [ 0.531  0.058 -0.379 ...,  0.004  0.164  0.020]\n",
        " [ 2.758  0.009 -0.031 ...,  0.012  0.110  0.017]\n",
        " ..., \n",
        " [ 1.628  0.043 -0.240 ...,  0.003  0.134  0.015]\n",
        " [ 8.192  0.050  0.935 ...,  0.009  0.116  0.019]\n",
        " [ 2.771  0.077 -0.167 ...,  0.004  0.218  0.026]]\n"
       ]
      }
     ],
     "prompt_number": 506
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question 3\n",
      "from scipy.cluster.hierarchy import linkage, dendrogram\n",
      "\n",
      "tfidf_Q3 = leastSquares(tfidfScores,100)\n",
      "print tfidf_Q3.shape\n",
      "dmDocs = function2(tfidf_Q3,cosine)\n",
      "\n",
      "dendro = dendrogram(linkage(dmDocs,method='complete'),orientation='right')\n",
      "type(dendro)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(178, 6488)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 414,
       "text": [
        "dict"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEDCAYAAAAhsS8XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f2368db6a10>"
       ]
      }
     ],
     "prompt_number": 414
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question 4\n",
      "# A = U*sigma*V\n",
      "# (mxn) = (mxm)(mxn)(nxn)\n",
      "# New: A = U*sigma*V\n",
      "# (mxn) = (mxp)(pxp)(pxn)\n",
      "\n",
      "# Change: tfidf(A) = U*sigma*t(D)\n",
      "# t(D) = inv(sigma)*t(U)*tfidf(A) => transposed documents\n",
      "\n",
      "mystery = open('mystery.txt').read()\n",
      "new_docs = {'mystery': mystery}\n",
      "\n",
      "# Calculate the tf-idf matrix for mystery.txt\n",
      "# query = np.dot(np.dot(np.linalg.inv(np.diag(s_new)),U_new.T),v_desiredMat)\n",
      "# Calculate the query vector: D = inv(sigma_k)*t(T_k)*A\n",
      "# A is the tfidf matrix\n",
      "\n",
      "# Remove the new words and get v_desiredMat (tf score of mystery.txt)\n",
      "v_tfidfScores, v_wordUnion, v_separate = tfidf(new_docs)\n",
      "v_desired = [val for val in wordUnion if val in v_wordUnion]\n",
      "v_desired_ind = []\n",
      "for text in v_desired:\n",
      "    v_desired_ind.append(v_wordUnion.index(text))\n",
      "\n",
      "# v_desiredMat = the v_tfidfScores only for the words existing in the original corpus\n",
      "v_desiredMat = np.zeros((1,len(v_desired)))\n",
      "another_ind = 0\n",
      "for i in v_desired_ind:\n",
      "    v_desiredMat[0,another_ind] = v_tfidfScores[0,i]\n",
      "    another_ind += 1\n",
      "    \n",
      "\n",
      "import scipy.linalg as la\n",
      "U, s, D = la.svd(tfidfScores, full_matrices=False)\n",
      "s_new = s[0:k] # indices: the last boundary is NOT included\n",
      "U_new = U[:,0:k]\n",
      "D_new = D[0:k,:]\n",
      "\n",
      "print D_new\n",
      "\n",
      "tfidf_Q4 = leastSquares(tfidfScores,10)\n",
      "compared_docs = tfidf_Q4[:,v_desired_ind] # 178*191\n",
      "# All 178 documents in the corpus, extracting only the 191 words obtained in mystery.txt\n",
      "\n",
      "similarCos = np.ones((1,compared_docs.shape[0]))\n",
      "for i in range(compared_docs.shape[0]):\n",
      "    # similarCos[0,i] = np.dot(v_desiredMat,compared_docs[i,:])/(np.linalg.norm(v_desiredMat)*np.linalg.norm(compared_docs[i,:]))\n",
      "    similarCos[0,i] = 1-cosine(v_desiredMat,compared_docs[i,:])\n",
      "    \n",
      "print similarCos.shape\n",
      "\n",
      "indices = similarCos.argsort()\n",
      "print similarCos.argsort().shape\n",
      "print similarCos[0,indices[0,0:10]] # the 10 documents least similarity \n",
      "print similarCos[0,indices[0,168:178]] # the 10 documents most similarity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-0.157 -0.001 -0.032 ..., -0.000 -0.004 -0.001]\n",
        " [ 0.011 -0.000  0.064 ..., -0.000 -0.004 -0.000]\n",
        " [ 0.063 -0.000  0.044 ...,  0.000  0.000  0.000]\n",
        " ..., \n",
        " [ 0.045 -0.001  0.026 ..., -0.000 -0.001 -0.000]\n",
        " [ 0.051 -0.000 -0.007 ...,  0.000  0.001  0.001]\n",
        " [-0.120  0.002 -0.022 ..., -0.000  0.002  0.000]]\n",
        "(1, 178)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(1, 178)\n",
        "[-0.112 -0.108 -0.107 -0.107 -0.106 -0.105 -0.105 -0.105 -0.105 -0.105]\n",
        "[-0.045 -0.040 -0.038 -0.036 -0.035 -0.035 -0.029 -0.016  0.028  0.046]\n"
       ]
      }
     ],
     "prompt_number": 516
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question 5\n",
      "print \"No, the boilerplate materials do not matter in either LSA-based clustering (part 3) or information retrieval (part 4). \"\n",
      "print \"Because these materials appear in every document, the relative distance between documents will not change.\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "No, the boilerplate materials do not matter in either LSA-based clustering (part 3) or information retrieval (part 4). \n",
        "Because these materials appear in every document, the relative distance between documents will not change.\n"
       ]
      }
     ],
     "prompt_number": 480
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notes on the Pubmed articles\n",
      "----\n",
      "\n",
      "These were downloaded with the following script. You don't have to download them by yourself!\n",
      "\n",
      "```python\n",
      "from Bio import Entrez, Medline\n",
      "Entrez.email = \"YOUR EMAIL HERE\"\n",
      "import cPickle\n",
      "\n",
      "try:\n",
      "    docs = cPickle.load(open('pubmed.pic'))\n",
      "except Exception, e:\n",
      "    print e\n",
      "\n",
      "    docs = {}\n",
      "    for term in ['plasmodium', 'diabetes', 'asthma', 'cytometry']:\n",
      "        handle = Entrez.esearch(db=\"pubmed\", term=term, retmax=50)\n",
      "        result = Entrez.read(handle)\n",
      "        handle.close()\n",
      "        idlist = result[\"IdList\"]\n",
      "        handle2 = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\")\n",
      "        result2 = Medline.parse(handle2)\n",
      "        for record in result2:\n",
      "            title = record.get(\"TI\", None)\n",
      "            abstract = record.get(\"AB\", None)\n",
      "            if title is None or abstract is None:\n",
      "                continue\n",
      "            docs[title] = '\\n'.join([title, abstract])\n",
      "            print title\n",
      "        handle2.close()\n",
      "    cPickle.dump(docs, open('pubmed.pic', 'w'))\n",
      "docs.values()\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}